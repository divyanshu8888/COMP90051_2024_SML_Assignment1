{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8F1Fnf3fMCU5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, SpatialDropout1D, LSTM, Dropout, Dense, Bidirectional\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Layer, Input, Flatten\n",
        "from keras.models import Model\n",
        "import keras.backend as K\n",
        "from keras.regularizers import l2\n",
        "from keras.initializers import Constant\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.initializers import Constant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XeZpOvBrL5Oo"
      },
      "outputs": [],
      "source": [
        "df1 = pd.read_json(\"/content/domain1_train_data.json\", lines=True)\n",
        "df2 = pd.read_json(\"/content/domain2_train_data.json\", lines=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "65UL6lAS4Pya"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# from imblearn.over_sampling import SMOTE\n",
        "# from imblearn.pipeline import Pipeline as IMPipeline  # Use imblearn's pipeline to handle SMOTE correctly\n",
        "\n",
        "# # Load data\n",
        "# df1 = pd.read_json(\"domain1_train_data.json\", lines=True)\n",
        "# df2 = pd.read_json(\"domain2_train_data.json\", lines=True)\n",
        "\n",
        "# # Convert lists of integers to strings for TF-IDF vectorization\n",
        "# df1['text'] = df1['text'].apply(lambda x: ' '.join(map(str, x)))\n",
        "# df2['text'] = df2['text'].apply(lambda x: ' '.join(map(str, x)))\n",
        "\n",
        "# # Split data for Domain 1 and Domain 2\n",
        "# X_train1, X_test1, y_train1, y_test1 = train_test_split(df1['text'], df1['label'], test_size=0.2, random_state=42)\n",
        "# X_train2, X_test2, y_train2, y_test2 = train_test_split(df2['text'], df2['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# # Concatenate data for combined training\n",
        "# combined_train_text = pd.concat([df1['text'], df2['text']])\n",
        "# combined_train_label = pd.concat([df1['label'], df2['label']])\n",
        "# X_train_combined, X_test_combined, y_train_combined, y_test_combined = train_test_split(\n",
        "#     combined_train_text, combined_train_label, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Create an imblearn pipeline with TF-IDF vectorizer, SMOTE, and SVM\n",
        "# pipeline = IMPipeline([\n",
        "#     ('tfidf', TfidfVectorizer(max_df=0.75, ngram_range=(1, 2))),\n",
        "#     ('smote', SMOTE(random_state=42)),\n",
        "#     ('svm', SVC(C=1, gamma='scale', probability=True))\n",
        "# ])\n",
        "\n",
        "# # Train and evaluate for Domain 1 with SMOTE\n",
        "# pipeline.fit(X_train1, y_train1)\n",
        "# y_pred1 = pipeline.predict(X_test1)\n",
        "# accuracy1 = accuracy_score(y_test1, y_pred1)\n",
        "# print(f'Domain 1 Test Accuracy with SVM and SMOTE: {accuracy1}')\n",
        "\n",
        "# # Train and evaluate for Domain 2 with SMOTE\n",
        "# pipeline.fit(X_train2, y_train2)\n",
        "# y_pred2 = pipeline.predict(X_test2)\n",
        "# accuracy2 = accuracy_score(y_test2, y_pred2)\n",
        "# print(f'Domain 2 Test Accuracy with SVM and SMOTE: {accuracy2}')\n",
        "\n",
        "# # Train and evaluate for Combined Data with SMOTE\n",
        "# pipeline.fit(X_train_combined, y_train_combined)\n",
        "# y_pred_combined = pipeline.predict(X_test_combined)\n",
        "# accuracy_combined = accuracy_score(y_test_combined, y_pred_combined)\n",
        "# print(f'Combined Test Accuracy with SVM and SMOTE: {accuracy_combined}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JHDhFhyNM3lq"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# from sklearn.pipeline import Pipeline\n",
        "\n",
        "# # Load data\n",
        "# df1 = pd.read_json(\"/content/domain1_train_data.json\", lines=True)\n",
        "\n",
        "# # Convert list of integers to space-separated strings for vectorization\n",
        "# df1['text'] = df1['text'].apply(lambda x: ' '.join(map(str, x)))\n",
        "\n",
        "# # Prepare the data\n",
        "# X = df1['text']\n",
        "# y = df1['label']\n",
        "\n",
        "# # Split data\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Define the pipeline with enhanced TF-IDF parameters\n",
        "# pipeline = Pipeline([\n",
        "#     ('tfidf', TfidfVectorizer(max_df=0.85, min_df=2, ngram_range=(1, 2))),\n",
        "#     ('classifier', SVC(probability=True))\n",
        "# ])\n",
        "\n",
        "# # Set up the grid search to find the best SVM parameters\n",
        "# param_grid = {\n",
        "#     'classifier__C': [1, 10],\n",
        "#     'classifier__gamma': [1, 0.1, 0.01, 0.001],\n",
        "#     'classifier__kernel': ['rbf', 'linear']\n",
        "# }\n",
        "\n",
        "# grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
        "# grid_search.fit(X_train, y_train)\n",
        "\n",
        "# # Evaluate the best model found by the grid search\n",
        "# y_pred = grid_search.predict(X_test)\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# # Output results\n",
        "# print(f'Best Parameters: {grid_search.best_params_}')\n",
        "# print(f'Enhanced Accuracy: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wBOKybP6eKe8"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# from sklearn.pipeline import Pipeline\n",
        "\n",
        "# # Load data\n",
        "# df1 = pd.read_json(\"/content/domain2_train_data.json\", lines=True)\n",
        "# df1['text'] = df1['text'].apply(lambda x: ' '.join(map(str, x)))\n",
        "# X = df1['text']\n",
        "# y = df1['label']\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# # Pipeline setup\n",
        "# pipeline = Pipeline([\n",
        "#     ('tfidf', TfidfVectorizer(max_df=0.85, min_df=2, ngram_range=(1, 2))),\n",
        "#     ('classifier', SVC(probability=True))\n",
        "# ])\n",
        "\n",
        "# # Setup parameter grid\n",
        "# param_grid = {\n",
        "#     'classifier__C': [1, 10],\n",
        "#     'classifier__gamma': ['scale'],\n",
        "#     'classifier__kernel': ['rbf']\n",
        "# }\n",
        "\n",
        "# # Execute randomized search\n",
        "# random_search = RandomizedSearchCV(pipeline, param_grid, n_iter=10, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "# random_search.fit(X_train, y_train)\n",
        "\n",
        "# # Evaluate the best model\n",
        "# y_pred = random_search.predict(X_test)\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# print(f'Best Parameters: {random_search.best_params_}')\n",
        "# print(f'Enhanced Accuracy: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4uOQ1EvZba5",
        "outputId": "88a3b8f2-5f02-4037-923d-0edb8984d9fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 2 is smaller than n_iter=5. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as IMPipeline\n",
        "from scipy.sparse import vstack\n",
        "\n",
        "# Load data\n",
        "df1 = pd.read_json(\"/content/domain1_train_data.json\", lines=True)\n",
        "df1['text'] = df1['text'].apply(lambda x: ' '.join(map(str, x)))\n",
        "df2 = pd.read_json(\"/content/domain2_train_data.json\", lines=True)\n",
        "df2['text'] = df2['text'].apply(lambda x: ' '.join(map(str, x)))\n",
        "\n",
        "# Split data\n",
        "X1 = df1['text']\n",
        "y1 = df1['label']\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
        "\n",
        "X2 = df2['text']\n",
        "y2 = df2['label']\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize text data\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.75, min_df=5, ngram_range=(1, 2),max_features=5000)\n",
        "X_train2_vectorized = tfidf_vectorizer.fit_transform(X_train2)\n",
        "X_train1_vectorized = tfidf_vectorizer.transform(X_train1)\n",
        "\n",
        "# Apply SMOTE to Domain 2 training data only after vectorization\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train2_smote, y_train2_smote = smote.fit_resample(X_train2_vectorized, y_train2)\n",
        "\n",
        "# Combine the vectorized and SMOTEd training data from both domains\n",
        "X_train_combined = vstack([X_train1_vectorized, X_train2_smote])\n",
        "y_train_combined = pd.concat([y_train1, y_train2_smote])\n",
        "\n",
        "# Vectorize the test data from both domains\n",
        "X_test1_vectorized = tfidf_vectorizer.transform(X_test1)\n",
        "X_test2_vectorized = tfidf_vectorizer.transform(X_test2)\n",
        "X_test_combined = vstack([X_test1_vectorized, X_test2_vectorized])\n",
        "y_test_combined = pd.concat([y_test1, y_test2])\n",
        "\n",
        "# Setup and train the pipeline\n",
        "pipeline = IMPipeline([\n",
        "    ('classifier', SVC(C=1, gamma='scale', probability=True))\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'classifier__C': [1, 10],\n",
        "    'classifier__gamma': ['scale'],\n",
        "    'classifier__kernel': ['rbf']\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(pipeline, param_grid, n_iter=5, cv=3, scoring='accuracy', n_jobs=-1, verbose=3)\n",
        "random_search.fit(X_train_combined, y_train_combined)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_combined = random_search.predict(X_test_combined)\n",
        "accuracy_combined = accuracy_score(y_test_combined, y_pred_combined)\n",
        "\n",
        "# Print detailed evaluation metrics\n",
        "print(f'Best Parameters: {random_search.best_params_}')\n",
        "print(f'Enhanced Accuracy on combined data: {accuracy_combined}')\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_combined, y_pred_combined))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_combined, y_pred_combined))\n",
        "\n",
        "# Print CV results for each fold to analyze variance and performance\n",
        "print(\"Detailed CV results:\")\n",
        "cv_results = pd.DataFrame(random_search.cv_results_)\n",
        "print(cv_results[['param_classifier__C', 'param_classifier__gamma', 'mean_test_score', 'std_test_score']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SusMkoMohbpb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming `random_search` and `tfidf_vectorizer` are already available in the session from previous training.\n",
        "\n",
        "# Load the test data\n",
        "test_data = pd.read_json(\"/content/test_data.json\", lines=True)\n",
        "test_data['text'] = test_data['text'].apply(lambda x: ' '.join(map(str, x)))\n",
        "\n",
        "# Transform the test data using the already loaded vectorizer\n",
        "X_test_new = tfidf_vectorizer.transform(test_data['text'])\n",
        "\n",
        "# Use the trained model to make predictions\n",
        "predicted_labels = random_search.predict(X_test_new)\n",
        "\n",
        "# Create a DataFrame with the predictions and IDs\n",
        "results_df = pd.DataFrame({\n",
        "    'id': test_data['id'],\n",
        "    'predicted_label': predicted_labels\n",
        "})\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results_df.to_csv('/content/predicted_labels.csv', index=False)\n",
        "\n",
        "print(\"Predictions have been saved to predicted_labels.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}