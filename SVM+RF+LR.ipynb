{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JQea4B37vXk",
        "outputId": "2264488f-2de6-4404-f777-7121f036114a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 1/3 [00:03<00:06,  3.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression trained. Accuracy: 0.8560714285714286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2/3 [52:55<31:07, 1867.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM trained. Accuracy: 0.7992857142857143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [53:53<00:00, 1077.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest trained. Accuracy: 0.9042857142857142\n",
            "Ensemble Model Accuracy: 0.9146428571428571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from scipy.sparse import vstack\n",
        "from sklearn.linear_model import LogisticRegression  # Meta-learner\n",
        "from tqdm import tqdm  # Import tqdm for progress tracking\n",
        "\n",
        "# Load and prepare data\n",
        "df_domain1 = pd.read_json(\"/content/domain1_train_data.json\", lines=True)\n",
        "df_domain1['text'] = df_domain1['text'].apply(lambda x: ' '.join(map(str, x)))\n",
        "\n",
        "df_domain2 = pd.read_json(\"/content/domain2_train_data.json\", lines=True)\n",
        "df_domain2['text'] = df_domain2['text'].apply(lambda x: ' '.join(map(str, x)))\n",
        "\n",
        "# Vectorize text\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_domain1 = vectorizer.fit_transform(df_domain1['text'])\n",
        "y_domain1 = df_domain1['label']\n",
        "\n",
        "X_domain2 = vectorizer.transform(df_domain2['text'])\n",
        "y_domain2 = df_domain2['label']\n",
        "\n",
        "# Apply SMOTE to Domain 2\n",
        "smote = SMOTE(random_state=42)\n",
        "X_domain2_balanced, y_domain2_balanced = smote.fit_resample(X_domain2, y_domain2)\n",
        "\n",
        "# Combine the datasets\n",
        "X_combined = vstack([X_domain1, X_domain2_balanced])\n",
        "y_combined = pd.concat([pd.Series(y_domain1), pd.Series(y_domain2_balanced)])\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combined, y_combined, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'SVM': SVC(probability=True,kernel='linear', C=0.1),\n",
        "    'Random Forest': RandomForestClassifier()\n",
        "}\n",
        "\n",
        "# Train and evaluate each model, collect predictions\n",
        "train_preds = []\n",
        "test_preds = []\n",
        "\n",
        "# Initialize tqdm for progress tracking\n",
        "pbar = tqdm(total=len(models))\n",
        "\n",
        "for name, model in models.items():\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Get predictions\n",
        "    train_pred = model.predict_proba(X_train)[:, 1]  # Use predict_proba for meta-learner training\n",
        "    test_pred = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Append predictions\n",
        "    train_preds.append(train_pred)\n",
        "    test_preds.append(test_pred)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, model.predict(X_test))\n",
        "\n",
        "    # Print progress message\n",
        "    print(f\"{name} trained. Accuracy: {accuracy}\")\n",
        "\n",
        "    # Update progress bar\n",
        "    pbar.update(1)\n",
        "\n",
        "# Close progress bar\n",
        "pbar.close()\n",
        "\n",
        "# Stack predictions as new features for the meta-learner\n",
        "X_train_meta = np.column_stack(train_preds)\n",
        "X_test_meta = np.column_stack(test_preds)\n",
        "\n",
        "# Define and train the meta-learner\n",
        "meta_learner = LogisticRegression()\n",
        "meta_learner.fit(X_train_meta, y_train)\n",
        "\n",
        "# Evaluate the ensemble\n",
        "final_predictions = meta_learner.predict(X_test_meta)\n",
        "ensemble_accuracy = accuracy_score(y_test, final_predictions)\n",
        "print(\"Ensemble Model Accuracy:\", ensemble_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from scipy.sparse import vstack\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Assuming your training code is here...\n",
        "\n",
        "# Load the test dataset\n",
        "df_test = pd.read_json(\"/content/test_data.json\", lines=True)\n",
        "# If 'text' contains lists of token IDs, assume they need to be converted to strings\n",
        "df_test['text'] = df_test['text'].apply(lambda ids: ' '.join(str(id) for id in ids))\n",
        "\n",
        "# Vectorize the test data using the existing vectorizer\n",
        "X_test_new = vectorizer.transform(df_test['text'])\n",
        "\n",
        "# Collect predictions from each base model for the new test data\n",
        "test_preds_new = []\n",
        "for name, model in models.items():\n",
        "    test_pred_new = model.predict_proba(X_test_new)[:, 1]  # assuming binary classification\n",
        "    test_preds_new.append(test_pred_new)\n",
        "\n",
        "# Stack these predictions to use as input for the meta-learner\n",
        "X_test_meta_new = np.column_stack(test_preds_new)\n",
        "\n",
        "# Use the meta-learner to make final predictions\n",
        "final_predictions_new = meta_learner.predict(X_test_meta_new)\n",
        "\n",
        "# Export the predictions to a CSV file\n",
        "results_df = pd.DataFrame({\n",
        "    'ID': df_test['id'],\n",
        "    'Predicted_Label': final_predictions_new\n",
        "})\n",
        "results_df.to_csv('predictions.csv', index=False)\n",
        "\n",
        "print(\"Predictions exported to predictions.csv.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzC07xY-q56x",
        "outputId": "fae6200a-f80f-4db5-f59b-aa32cbde9244"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions exported to predictions.csv.\n"
          ]
        }
      ]
    }
  ]
}