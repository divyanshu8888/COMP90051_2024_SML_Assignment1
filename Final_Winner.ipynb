{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8F1Fnf3fMCU5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, SpatialDropout1D, LSTM, Dropout, Dense, Bidirectional\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Layer, Input, Flatten\n",
        "from keras.models import Model\n",
        "import keras.backend as K\n",
        "from keras.regularizers import l2\n",
        "from keras.initializers import Constant\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.initializers import Constant\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC  # Ensure this import is included\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as IMPipeline\n",
        "from scipy.sparse import vstack\n",
        "from joblib import parallel_backend\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeZpOvBrL5Oo"
      },
      "outputs": [],
      "source": [
        "df1 = pd.read_json(\"/content/domain1_train_data.json\", lines=True)\n",
        "df2 = pd.read_json(\"/content/domain2_train_data.json\", lines=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux1q_UrGdEzj",
        "outputId": "b5779bc1-a873-409f-bfd6-9172939e7030"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Voting Classifier Accuracy: 0.888\n",
            "Voting Classifier ROC AUC: 0.9309974170156102\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.86      0.88       237\n",
            "           1       0.88      0.91      0.90       263\n",
            "\n",
            "    accuracy                           0.89       500\n",
            "   macro avg       0.89      0.89      0.89       500\n",
            "weighted avg       0.89      0.89      0.89       500\n",
            "\n",
            "Confusion Matrix:\n",
            "[[204  33]\n",
            " [ 23 240]]\n",
            "Optimal threshold: 0.49642714691949585\n",
            "Sample misclassified texts: 4767    2029 2856 107 1 16 395 2 4699 118 1 8977 9 728...\n",
            "4651    500 118 18 65 3871 6 97 7 122 50 1 7590 25 33 ...\n",
            "210     14041 9 702 18 7 91 1425 781 1 55 42 186 7 629...\n",
            "279     91 3547 32402 31 62 110 4069 31 16 74 531 24 1...\n",
            "2940    16 258 96 2 107 36 13966 19 37 6 2 135 8 2 186...\n",
            "Name: text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\n",
        "from sklearn.metrics import roc_curve\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Function to load and preprocess data\n",
        "def preprocess_data(file_path):\n",
        "    df = pd.read_json(file_path, lines=True)\n",
        "    df['text'] = df['text'].apply(lambda x: ' '.join(map(str, x)))\n",
        "    return df\n",
        "\n",
        "# Load datasets\n",
        "df1 = preprocess_data('/content/domain1_train_data.json')\n",
        "# df2 = preprocess_data('domain2_train_data.json')\n",
        "# data=preprocess_data('/content/imbalanced_domain2_train_data.json')\n",
        "data2=preprocess_data('/content/balanced_domain1_train_data.json')\n",
        "# Combine datasets\n",
        "# full_data = pd.concat([df1,df2])\n",
        "full_data=df1\n",
        "X = full_data['text']\n",
        "y = full_data['label']\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Create TF-IDF vectorizer\n",
        "tfidf = TfidfVectorizer(max_df=0.50, min_df=2, ngram_range=(1,7))\n",
        "\n",
        "# Initialize classifiers\n",
        "lr_model = LogisticRegression(C=10, max_iter=1000, random_state=42, solver='liblinear', class_weight='balanced')\n",
        "sgd_model = SGDClassifier(max_iter=5000, loss='modified_huber', random_state=42, class_weight='balanced')\n",
        "rf_model = RandomForestClassifier(n_estimators=100,max_features='sqrt', random_state=42, class_weight='balanced')\n",
        "svm_model = SVC(C=10,probability=True, kernel='rbf',gamma='scale',class_weight='balanced', random_state=42)\n",
        "\n",
        "\n",
        "# Create TF-IDF vectorizer\n",
        "tfidf = TfidfVectorizer(max_df=0.55, min_df=2, ngram_range=(1, 7))\n",
        "\n",
        "# Initialize Voting Classifier\n",
        "voting_clf = VotingClassifier(estimators=[\n",
        "    ('lr', lr_model),\n",
        "    ('sgd', sgd_model)\n",
        "], voting='soft', weights=[1,0.9])  # Adjust the weights and voting strategy as needed\n",
        "\n",
        "# Create pipeline with the TF-IDF vectorizer, scaler, and voting classifier\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', tfidf),\n",
        "    ('scaler', StandardScaler(with_mean=False)),  # Necessary for sparse matrix handling\n",
        "    ('voting_clf', voting_clf)\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities and labels\n",
        "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
        "threshold = 0.5  # Adjust based on your needs\n",
        "y_pred = (y_proba >= threshold).astype(int)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Voting Classifier Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Voting Classifier ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Calculate the ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
        "\n",
        "# Find the optimal threshold\n",
        "optimal_idx = np.argmax(tpr - fpr)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "print(\"Optimal threshold:\", optimal_threshold)\n",
        "\n",
        "# Analyze misclassifications\n",
        "misclassified = X_test[y_test != y_pred]\n",
        "print(\"Sample misclassified texts:\", misclassified.sample(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8UX9__0MSUEP",
        "outputId": "4b526750-91ba-40ca-957a-a7a34d2cb352"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stacking Classifier Accuracy: 0.8625\n",
            "Stacking Classifier ROC AUC: 0.9522986519184238\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.92      0.86       263\n",
            "           1       0.92      0.81      0.86       297\n",
            "\n",
            "    accuracy                           0.86       560\n",
            "   macro avg       0.87      0.87      0.86       560\n",
            "weighted avg       0.87      0.86      0.86       560\n",
            "\n",
            "Confusion Matrix:\n",
            "[[243  20]\n",
            " [ 57 240]]\n",
            "Optimal threshold: 0.43018831671400043\n",
            "Sample misclassified texts: 1694    39 7 122 1599 28 2 1230 369 1 34 32 138 15589 ...\n",
            "4248    2 1673 1674 393 8 8879 31 2 1553 9 1569 3 40 3...\n",
            "3625    15 45 5 24 2 123 12271 6 11313 7194 16 19 302 ...\n",
            "1173    127 12 441 130 2 15742 3 15 1890 96 7 17932 1 ...\n",
            "3608    12408 72 23233 82 2 58 383 2611 95 34 22 3205 ...\n",
            "Name: text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Function to load and preprocess data\n",
        "def preprocess_data(file_path):\n",
        "    df = pd.read_json(file_path, lines=True)\n",
        "    df['text'] = df['text'].apply(lambda x: ' '.join(map(str, x)))\n",
        "    return df\n",
        "\n",
        "# Load datasets\n",
        "df1 = preprocess_data('/content/domain1_train_data.json')\n",
        "data2 = preprocess_data('/content/balanced_domain1_train_data.json')\n",
        "df2=preprocess_data('/content/domain2_train_data.json')\n",
        "\n",
        "# Combine datasets\n",
        "# full_data = df1\n",
        "full_data = pd.concat([df1, data2])\n",
        "X = full_data['text']\n",
        "y = full_data['label']\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Create TF-IDF vectorizer\n",
        "tfidf = TfidfVectorizer(max_df=0.50, min_df=2, ngram_range=(1,7))\n",
        "\n",
        "# Initialize classifiers\n",
        "lr_model = LogisticRegression(C=10, max_iter=1000, random_state=42, solver='liblinear', class_weight='balanced')\n",
        "lr_model1 = LogisticRegression(C=10, max_iter=1000, random_state=42, solver='liblinear', class_weight='balanced')\n",
        "sgd_model = SGDClassifier(max_iter=5000, loss='modified_huber', random_state=42, class_weight='balanced')\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
        "svm_model = SVC(C=10, probability=True, kernel='rbf', gamma='scale', class_weight='balanced', random_state=42)\n",
        "\n",
        "\n",
        "# Initialize Stacking Classifier with Logistic Regression as the final estimator\n",
        "final_lr = LogisticRegression(C=10, max_iter=1000, random_state=42, solver='liblinear', class_weight='balanced')\n",
        "stacking_clf = StackingClassifier(estimators=[\n",
        "    ('lr', lr_model),\n",
        "    # ('lr1',lr_model1),\n",
        "    ('sgd', sgd_model),\n",
        "    ('rf', rf_model),\n",
        "    # ('nb',nb_model)\n",
        "    ('svm', svm_model)\n",
        "], final_estimator=final_lr, passthrough=True)\n",
        "\n",
        "# Create pipeline with the TF-IDF vectorizer and the stacking classifier\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', tfidf),\n",
        "    # ('scaler', StandardScaler(with_mean=False)),\n",
        "    ('smote', BorderlineSMOTE(kind='borderline-2',random_state=42)),# Necessary for sparse matrix handling\n",
        "    ('stacking_clf', stacking_clf)\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities and labels\n",
        "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
        "threshold = 0.5  # Adjust based on your needs\n",
        "y_pred = (y_proba >= threshold).astype(int)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Stacking Classifier Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Stacking Classifier ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Calculate the ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
        "\n",
        "# Find the optimal threshold\n",
        "optimal_idx = np.argmax(tpr - fpr)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "print(\"Optimal threshold:\", optimal_threshold)\n",
        "\n",
        "# Analyze misclassifications\n",
        "misclassified = X_test[y_test != y_pred]\n",
        "print(\"Sample misclassified texts:\", misclassified.sample(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFjLXBtF_yYP",
        "outputId": "5efd4e5f-ed60-40b3-9c8e-c14f5cedd7d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions have been saved to predicted_labels.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the test data\n",
        "test_data = pd.read_json(\"/content/test_data.json\", lines=True)\n",
        "test_data['text'] = test_data['text'].apply(lambda x: ' '.join(map(str, x)))\n",
        "\n",
        "# Ensure the tfidf variable used in the original training is not used here. Use the pipeline directly for predictions.\n",
        "\n",
        "# Use the trained pipeline to make predictions directly on the text data\n",
        "predicted_labels = pipeline.predict_proba(test_data['text'])[:, 1]\n",
        "threshold = 0.4  # Adjust based on your needs\n",
        "y_pred = (predicted_labels >= threshold).astype(int)\n",
        "\n",
        "# Create a DataFrame with the predictions and IDs\n",
        "results_df = pd.DataFrame({\n",
        "    'id': test_data['id'],\n",
        "    'label': y_pred\n",
        "})\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results_df.to_csv('/content/predicted_labels.csv', index=False)\n",
        "\n",
        "print(\"Predictions have been saved to predicted_labels.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ynaFBqwETJU"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wb9iNLVyRwEC",
        "outputId": "b26b4f08-1dc1-4633-831a-61917d9940a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC: 0.9999936473349776\n",
            "Accuracy: 0.9988095238095238\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      2051\n",
            "           1       1.00      1.00      1.00      2149\n",
            "\n",
            "    accuracy                           1.00      4200\n",
            "   macro avg       1.00      1.00      1.00      4200\n",
            "weighted avg       1.00      1.00      1.00      4200\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2051    0]\n",
            " [   5 2144]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Function to load and preprocess data\n",
        "def preprocess_data(file_path):\n",
        "    df = pd.read_json(file_path, lines=True)\n",
        "    df['text'] = df['text'].apply(lambda x: ' '.join(map(str, x)))\n",
        "    return df\n",
        "\n",
        "# Load datasets\n",
        "datasets = [preprocess_data(f\"undersample_{i}.json\") for i in range(1, 8)]\n",
        "full_data = pd.concat(datasets)\n",
        "X = full_data['text']\n",
        "y = full_data['label']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create TF-IDF vectorizer\n",
        "tfidf = TfidfVectorizer(max_df=0.55, min_df=2, ngram_range=(1, 7))\n",
        "\n",
        "# Initialize classifiers with specific settings\n",
        "lr = LogisticRegression(max_iter=1000, random_state=42, C=10, class_weight='balanced', solver='liblinear')\n",
        "\n",
        "# Pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', tfidf),\n",
        "    ('scaler', StandardScaler(with_mean=False)),\n",
        "    ('classifier', lr)\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities and labels\n",
        "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
        "threshold = 0.45  # Adjust based on your needs\n",
        "y_pred = (y_proba >= threshold).astype(int)\n",
        "\n",
        "# Evaluation\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eg8MyWADzAIX",
        "outputId": "5fac8e73-5ae6-4f4f-cb07-d60e9811eb8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC: 0.9553617463958359\n",
            "Accuracy: 0.8494444444444444\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.99      0.91      1411\n",
            "           1       0.89      0.34      0.50       389\n",
            "\n",
            "    accuracy                           0.85      1800\n",
            "   macro avg       0.87      0.67      0.70      1800\n",
            "weighted avg       0.86      0.85      0.82      1800\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1395   16]\n",
            " [ 255  134]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# Load data\n",
        "df1 = pd.read_json(\"/content/domain1_train_data.json\", lines=True)\n",
        "df2 = pd.read_json(\"/content/domain2_train_data.json\", lines=True)\n",
        "df1['text'] = df1['text'].apply(lambda x: ' '.join(map(str, x)))\n",
        "df2['text'] = df2['text'].apply(lambda x: ' '.join(map(str, x)))\n",
        "\n",
        "# Combine and split data\n",
        "X = pd.concat([df1['text'], df2['text']])\n",
        "y = pd.concat([df1['label'], df2['label']])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "\n",
        "# Create TF-IDF vectorizer\n",
        "tfidf = TfidfVectorizer(max_df=0.85, min_df=1, ngram_range=(1, 9))\n",
        "\n",
        "# Initialize classifiers with specific settings\n",
        "lr = LogisticRegression(max_iter=1000, random_state=42, C=0.0001, class_weight='balanced',solver='liblinear')\n",
        "\n",
        "# Pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', tfidf),\n",
        "    ('scaler', StandardScaler(with_mean=False)),\n",
        "    ('classifier', lr)\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities and labels\n",
        "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
        "threshold = 0.5  # Adjust based on your needs\n",
        "y_pred = (y_proba >= threshold).astype(int)\n",
        "\n",
        "# Evaluation\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_J5VdwDWU5r",
        "outputId": "4811f8ad-a44a-420b-9e07-47d610218093"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions have been saved to predicted_labels.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the test data\n",
        "test_data = pd.read_json(\"/content/test_data.json\", lines=True)\n",
        "test_data['text'] = test_data['text'].apply(lambda x: ' '.join(map(str, x)))\n",
        "\n",
        "# Ensure the tfidf variable used in the original training is not used here. Use the pipeline directly for predictions.\n",
        "\n",
        "# Use the trained pipeline to make predictions directly on the text data\n",
        "predicted_labels = pipeline.predict_proba(test_data['text'])[:, 1]\n",
        "threshold = 0.1  # Adjust based on your needs\n",
        "y_pred = (predicted_labels >= threshold).astype(int)\n",
        "\n",
        "# Create a DataFrame with the predictions and IDs\n",
        "results_df = pd.DataFrame({\n",
        "    'id': test_data['id'],\n",
        "    'label': y_pred\n",
        "})\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results_df.to_csv('/content/predicted_labels.csv', index=False)\n",
        "\n",
        "print(\"Predictions have been saved to predicted_labels.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScKQ6lx7w6HQ"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}